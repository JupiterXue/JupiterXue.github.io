<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <link rel="preload" href="/lib/font-awesome/webfonts/fa-brands-400.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="preload" href="/lib/font-awesome/webfonts/fa-regular-400.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="preload" href="/lib/font-awesome/webfonts/fa-solid-900.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="preload" href="/lib/JetBrainsMono/web/woff2/JetBrainsMono-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title> Go 翻山越岭——内存模型 | 木夜星空的个人博客</title>
  <link rel = 'canonical' href = 'https://jupiterxue.github.io/go-to-top/day38-memory_model/'>
  <meta name="description" content="东方不亮木星亮，黑了白昼有星空">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="robots" content="all,follow">
  <meta name="googlebot" content="index,follow,snippet,archive">
  <meta property="og:title" content="Go 翻山越岭——内存模型" />
<meta property="og:description" content="今天聊一聊 Go 语言中的内存模型，这部分内容在对于利用 sync 库在进行应用开发中用处不大，不过我们在面试过程中可能会遇到，这里做个记录。
我们日常的开发中，只要知道使用显示同步就可以保证正确性。也就是说只要发生了并发的情况，那么一定要显示地使用同步手段。显示同步手段，通常是指 channel 或者锁。并且，能够用 channel 和锁的情况下，基本上，只要没有 race 出现，就能够保障程序的正确性。
但我们在开发中有时候会给别人提供偏底层的库，那么需要对底层有了解才能做得出来。因此就遇到了 Memory Model 内存模型。
Memory Model 在具体了解之前，我们先要了解目前的 CPU 架构。现代的 CPU 内部的存储其实都是分级的，比如以下就是个多核 CPU 的典型架构图：
在这个内部，我们可以看到 L1 cache，具体的信息可以通过命令 lscpu 查看到，如下图所示：
L1 cache 有两种类型： L1 Data cache 和 L1 Structure cache。我们平时在编程中经常遇到的就是 L1 Data cache，也就是在修改内存中变量的时候，一定需要从内存中一级一级地把它加载到 L3 → L2 → L1→ core 最终才能让 CPU 核心去处理数据。
L1 cache 又会被划分为多个更细粒度的 cache line，每个 cache line 的大小为 64 bytes。这就是我们为什么在程序中经常会看到，有些数据结构会在其最后不足的情况下补足为 64 字节或 128 字节，都是有可能发生的。我们在 Linux 中也可以再动动手去做些实践尝试一下这个命令：getconf LEVEL1_DCACHE_LINESIZE，可以看到 Data cache 的 cache line 长度，也就是 64 个字节。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://jupiterxue.github.io/go-to-top/day38-memory_model/" /><meta property="article:section" content="go-to-top" />
<meta property="article:published_time" content="2021-12-13T20:06:42+08:00" />
<meta property="article:modified_time" content="2021-12-13T20:06:42+08:00" />


  <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Go 翻山越岭——内存模型"/>
<meta name="twitter:description" content="今天聊一聊 Go 语言中的内存模型，这部分内容在对于利用 sync 库在进行应用开发中用处不大，不过我们在面试过程中可能会遇到，这里做个记录。
我们日常的开发中，只要知道使用显示同步就可以保证正确性。也就是说只要发生了并发的情况，那么一定要显示地使用同步手段。显示同步手段，通常是指 channel 或者锁。并且，能够用 channel 和锁的情况下，基本上，只要没有 race 出现，就能够保障程序的正确性。
但我们在开发中有时候会给别人提供偏底层的库，那么需要对底层有了解才能做得出来。因此就遇到了 Memory Model 内存模型。
Memory Model 在具体了解之前，我们先要了解目前的 CPU 架构。现代的 CPU 内部的存储其实都是分级的，比如以下就是个多核 CPU 的典型架构图：
在这个内部，我们可以看到 L1 cache，具体的信息可以通过命令 lscpu 查看到，如下图所示：
L1 cache 有两种类型： L1 Data cache 和 L1 Structure cache。我们平时在编程中经常遇到的就是 L1 Data cache，也就是在修改内存中变量的时候，一定需要从内存中一级一级地把它加载到 L3 → L2 → L1→ core 最终才能让 CPU 核心去处理数据。
L1 cache 又会被划分为多个更细粒度的 cache line，每个 cache line 的大小为 64 bytes。这就是我们为什么在程序中经常会看到，有些数据结构会在其最后不足的情况下补足为 64 字节或 128 字节，都是有可能发生的。我们在 Linux 中也可以再动动手去做些实践尝试一下这个命令：getconf LEVEL1_DCACHE_LINESIZE，可以看到 Data cache 的 cache line 长度，也就是 64 个字节。"/>

  
  
    
  
  
  <link rel="stylesheet" href="https://jupiterxue.github.io/css/styles.94f653e9e151e28067a7c5dbbc4600cbd5a3c721e79faaf971e523c40f3b249b8e4f20bb57810dfffa8d559ca5c140fd56eb4cd9c0853113ad08e66afdb08bdd.css" integrity="sha512-lPZT6eFR4oBnp8XbvEYAy9WjxyHnn6r5ceUjxA87JJuOTyC7V4EN//qNVZylwUD9VutM2cCFMROtCOZq/bCL3Q=="> 

  
  
  
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
  


  
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-xxxx"></script>
<script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-5QVC54HS9T');
</script>


  
<link rel="icon" type="image/png" href="https://jupiterxue.github.io/images/favicon.ico" />

  
  
  
  
</head>

<body class="max-width mx-auto px3 ltr">
  <div class="content index py4">

    <header id="header">
  <a href="https://jupiterxue.github.io/">
  
    <div id="logo" style="background-image: url(https://jupiterxue.github.io/images/logo.png)"></div>
  
  <div id="title">
    <h1>木夜星空的个人博客</h1>
  </div>
  </a>
  <div id="nav">
    <ul>
      <li class="icon">
        <a href="#" aria-label="Menu"><i class="fas fa-bars fa-2x" aria-hidden="true"></i></a>
      </li>
      
        <li><a href="/">主页</a></li>
      
        <li><a href="/go-to-top">Go 语言系列</a></li>
      
        <li><a href="/posts">杂谈</a></li>
      
        <li><a href="/tags">标签</a></li>
      
        <li><a href="/about">关于我</a></li>
      
    </ul>
  </div>
</header>



    
<article class="post" itemscope itemtype="http://schema.org/BlogPosting">

  <div class="content" itemprop="articleBody">
  
    <p>今天聊一聊 Go 语言中的内存模型，这部分内容在对于利用 sync 库在进行应用开发中用处不大，不过我们在面试过程中可能会遇到，这里做个记录。</p>
<p>我们日常的开发中，<strong>只要知道使用显示同步就可以保证正确性</strong>。也就是说只要发生了并发的情况，那么一定要显示地使用同步手段。显示同步手段，通常是指 channel 或者锁。并且，能够用 channel 和锁的情况下，基本上，只要没有 race 出现，就能够保障程序的正确性。</p>
<p>但我们在开发中有时候会给别人提供偏底层的库，那么需要对底层有了解才能做得出来。因此就遇到了 Memory Model 内存模型。</p>
<h1 id="memory-model">Memory Model</h1>
<p>在具体了解之前，我们先要了解目前的 CPU 架构。现代的 CPU 内部的存储其实都是分级的，比如以下就是个多核 CPU 的典型架构图：</p>
<p><img src="https://cdn.jsdelivr.net/gh/JupiterXue/PictureBed/BlogImg/202112132118518.png" alt="image-20211213211849363"></p>
<!-- raw HTML omitted -->
<p>在这个内部，我们可以看到 L1 cache，具体的信息可以通过命令 <strong>lscpu</strong> 查看到，如下图所示：</p>
<p><img src="https://cdn.jsdelivr.net/gh/JupiterXue/PictureBed/BlogImg/202112132125962.png" alt="image-20211213212551827"></p>
<!-- raw HTML omitted -->
<p>L1 cache 有两种类型： L1 Data cache 和 L1 Structure cache。我们平时在编程中经常遇到的就是 L1 Data cache，也就是在修改内存中变量的时候，一定需要从内存中一级一级地把它加载到 L3 → L2 → L1→ core 最终才能让 CPU 核心去处理数据。</p>
<p>L1 cache 又会被划分为多个更细粒度的 cache line，每个 cache line 的大小为 64 bytes。这就是我们为什么在程序中经常会看到，有些数据结构会在其最后不足的情况下补足为 64 字节或 128 字节，都是有可能发生的。我们在 Linux 中也可以再动动手去做些实践尝试一下这个命令：<strong>getconf LEVEL1_DCACHE_LINESIZE</strong>，可以看到 Data cache 的 cache line 长度，也就是 64 个字节。</p>
<p><img src="https://cdn.jsdelivr.net/gh/JupiterXue/PictureBed/BlogImg/202112132136195.png" alt="image-20211213213620134"></p>
<!-- raw HTML omitted -->
<p>这里还有两段 Go 语言 Runtime 源码中 cacheline pad 的代码，更加有助于我们理解：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-go" data-lang="go"><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1</span><span style="color:#66d9ef">var</span> <span style="color:#a6e22e">work</span> <span style="color:#66d9ef">struct</span> {
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">2</span>    <span style="color:#a6e22e">full</span>      <span style="color:#a6e22e">lfstack</span>			<span style="color:#75715e">// lock-free list of full blocks workbuf
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">3</span><span style="color:#75715e"></span>    <span style="color:#a6e22e">empty</span>  <span style="color:#a6e22e">lfstack</span>			 <span style="color:#75715e">// lock-free list of empty blocks workbuf
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">4</span><span style="color:#75715e"></span>    <span style="color:#a6e22e">pad0</span>    <span style="color:#a6e22e">cpu</span>.<span style="color:#a6e22e">CacheLinePad</span>     <span style="color:#75715e">// prevents false-sharing between full/empty and nproc/nwait
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">5</span><span style="color:#75715e"></span>}
</code></pre></div><p>pad0 能够补齐 struct 来避免一些 false-sharing 情况。这里结构较为简单后面再来说明。</p>
<p>现代计算机多核心能够提高效率，但多核心也给我们带来了一些问题：</p>
<ul>
<li>单变量的并发操作也必须使用同步手段，比如 atomic。</li>
<li>全局视角下观察到的多变量读写的顺序可能会乱序。</li>
</ul>
<p>也就是说，只要有全局的或共享的变量，那么我们在操作它们的时候，一定要使用同步手段，或者至少要需要是 atomic 的操作。另一方面，多变量的读写顺序在多核心的情况下有可能会被打乱。</p>
<p>先来看看单变量的原子读和写操作。为什么 atomic 可以保证当前进行了写操作，其他地方能够读取到？其实 atomic 也就是 CPU 提供的一些原始的指令。其内部的实现是通过多核心使用 Mesi 协议来保证的正确性，这里有张图：</p>
<p><img src="https://cdn.jsdelivr.net/gh/JupiterXue/PictureBed/BlogImg/202112132218409.png" alt="image-20211213221821307"></p>
<!-- raw HTML omitted -->
<p>Mesi 协议其实是简化过的描述，事实上不同的 CPU 实现的方式是不一样的，比如 Intel 和 AMD 实现的是不一样的。不过基本的 Mesi 协议可以这样理解：</p>
<ul>
<li>有四种状态分别是：M(Modified) 修改、E(Exclusive) 独占、S(Shared) 共享 和 I(Invalid) 失效；</li>
<li>多核在共享一个变量的时候会切换到 S 状态；</li>
<li>处于 I 状态，缓存中的数据已经失效了，如果想要对其进行读或写，必须从别的地方去拿。</li>
</ul>
<p>这些状态如何转换有个表格：</p>
<table>
<thead>
<tr>
<th></th>
<th style="text-align:center">p0</th>
<th style="text-align:center">p1</th>
<th style="text-align:center">p2</th>
<th style="text-align:center">p3</th>
</tr>
</thead>
<tbody>
<tr>
<td>Initial state</td>
<td style="text-align:center">I</td>
<td style="text-align:center">I</td>
<td style="text-align:center">I</td>
<td style="text-align:center">I</td>
</tr>
<tr>
<td>p0 reads X</td>
<td style="text-align:center">E</td>
<td style="text-align:center">I</td>
<td style="text-align:center">I</td>
<td style="text-align:center">I</td>
</tr>
<tr>
<td>p1 reads X</td>
<td style="text-align:center">S</td>
<td style="text-align:center">S</td>
<td style="text-align:center">I</td>
<td style="text-align:center">I</td>
</tr>
<tr>
<td>p2 reads X</td>
<td style="text-align:center">S</td>
<td style="text-align:center">S</td>
<td style="text-align:center">S</td>
<td style="text-align:center">I</td>
</tr>
<tr>
<td>p3 writes X</td>
<td style="text-align:center">I</td>
<td style="text-align:center">I</td>
<td style="text-align:center">I</td>
<td style="text-align:center">M</td>
</tr>
<tr>
<td>p0 readx X</td>
<td style="text-align:center">S</td>
<td style="text-align:center">I</td>
<td style="text-align:center">I</td>
<td style="text-align:center">S</td>
</tr>
</tbody>
</table>
<ul>
<li>最初的状态，里面每个核心对应的状态都是 Invalid；</li>
<li>当核心 p0 通过 atomic 去读取全局变量 X 时，经过了 Mesi 协议，因此将 p0 中的 cache line 变为 Exclusive 独占状态（如果其他核心想要读取 X 变量就会修改当前的状态）；</li>
<li>如果核心 p1 也需要读取 X，就会把之前 p0 的 cache line 修改为 Shared 的状态，并且 p0 和 p1 都持有了 X 其 cache line 状态都是 Shared 的状态；</li>
<li>这时候如果核心 p2 也读了 X，过程和上一个类似，也会变为 S 状态；</li>
<li>核心 p3 的的操作不一样了，它需要去写入 X，也是通过 atomic。就会把 X 这个变量加载到自己的 cache line 中，并且修改 X 的值，当前它的 cache line 的状态为 Modified，并且把其他所有核心为 S 状态的都修改为 Invalid。也就是说在它们之后需要用 X 的话就从别的地方去拿这个变量，现在的 X 已经不合法了；</li>
<li>然后，核心 p0 又要读 X，就会和核心 p3 一起都变为 Shared 状态。</li>
</ul>
<p>另外，国外顶尖大学 CMU 有一门课专门来讲了并发计算机的架构，非常好，建议感兴趣的读者可以自行去了解。</p>
<p>OK，下期继续讲解内存模型，看一看多核结构下还存在哪些问题，已经有什么样的解决方案。</p>
<p><strong>参考资料</strong></p>
<p>[1] A Modern Multi-Core Processor</p>
<p><a href="http://15418.courses.cs.cmu.edu/spring2015/lecture/basicarch/slide_042">http://15418.courses.cs.cmu.edu/spring2015/lecture/basicarch/slide_042</a></p>
<p>[2] MESI Cache Coherency Protocol</p>
<p><a href="https://www.scss.tcd.ie/Jeremy.Jones/VivioJS/caches/MESIHelp.htm">https://www.scss.tcd.ie/Jeremy.Jones/VivioJS/caches/MESIHelp.htm</a></p>

  

  </div>
</article>
  
  













  
  
  <div class="post bg-white">
    <script src="https://utteranc.es/client.js"
            repo= "JupiterXue/BlogComment"
            issue-term="title"
            theme="github-light"
    crossorigin="anonymous"
    async>
    </script>
  </div>
  




    <footer id="footer">
  <div class="footer-left">
    Copyright  &copy; 2022  JupiterXue 
  </div>
  <div class="footer-right">
    <nav>
      <ul>
         
        <li><a href="/">主页</a></li>
         
        <li><a href="/go-to-top">Go 语言系列</a></li>
         
        <li><a href="/posts">杂谈</a></li>
         
        <li><a href="/tags">标签</a></li>
         
        <li><a href="/about">关于我</a></li>
        
      </ul>
    </nav>
  </div>
</footer>


  </div>
</body>

<link rel="stylesheet" href=/lib/font-awesome/css/all.min.css>
<script src=/lib/jquery/jquery.min.js></script>
<script src=/js/main.js></script>
</html>
